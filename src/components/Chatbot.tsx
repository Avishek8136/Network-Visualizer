import React, { useState, useRef, useEffect } from 'react';
import { Send, Bot, User, MessageSquare, X, Minimize2, Maximize2 } from 'lucide-react';
import type { ChatMessage } from '../types';

interface ChatbotProps {
  currentModel?: string;
}

const Chatbot: React.FC<ChatbotProps> = ({ currentModel = 'Neural Networks' }) => {
  const [messages, setMessages] = useState<ChatMessage[]>([
    {
      id: '1',
      role: 'assistant',
      content: `Hello! üëã I'm your Neural Network Assistant with a built-in knowledge base. I can help you understand deep learning architectures, layers, training concepts, and applications!

üí° **Ask me about**:
‚Ä¢ Models: AlexNet, ResNet, GoogLeNet, VGG
‚Ä¢ Layers: Convolution, Pooling, Dropout, Batch Normalization, Activation Functions
‚Ä¢ Training: Optimizers, Learning Rates, Backpropagation
‚Ä¢ Concepts: Transfer Learning, Overfitting, Data Augmentation

**How I work**: I use pattern matching to provide relevant information from my comprehensive knowledge base.`,
      timestamp: new Date(),
    },
  ]);
  const [input, setInput] = useState('');
  const [isMinimized, setIsMinimized] = useState(false);
  const [isExpanded, setIsExpanded] = useState(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  const getAIResponse = (userMessage: string): string => {
    const lowerMessage = userMessage.toLowerCase();
    
    // Knowledge base for common questions
    if (lowerMessage.includes('alexnet')) {
      return "AlexNet (2012) was revolutionary! It's a deep CNN with 8 layers (5 convolutional + 3 fully connected) that won ImageNet 2012. Key innovations: ReLU activation, dropout regularization, overlapping pooling, and GPU training. It has ~60M parameters and achieved 15.3% top-5 error.";
    }
    
    if (lowerMessage.includes('resnet')) {
      return "ResNet introduced skip connections (residual learning) that allow gradients to flow directly through the network. This solved the vanishing gradient problem and enabled training of very deep networks (50, 101, 152 layers). ResNet-50 has ~25.6M parameters and uses bottleneck blocks for efficiency.";
    }
    
    if (lowerMessage.includes('googlenet') || lowerMessage.includes('inception')) {
      return "GoogLeNet (Inception v1, 2014) introduced Inception modules that use parallel convolutions of different sizes (1√ó1, 3√ó3, 5√ó5) to capture multi-scale features. Despite being deep (22 layers), it only has ~6.8M parameters thanks to 1√ó1 convolutions for dimensionality reduction. It also uses auxiliary classifiers during training.";
    }
    
    if (lowerMessage.includes('vgg')) {
      return "VGG-16 demonstrated that network depth is crucial for performance. It uses a simple, uniform architecture with only 3√ó3 convolutions stacked together. While very deep (16 layers), it has a huge number of parameters (~138M), mostly in the fully connected layers.";
    }
    
    if (lowerMessage.includes('convolution') || lowerMessage.includes('conv')) {
      return "Convolutional layers apply filters (kernels) to extract features from images. They use parameter sharing and local connectivity, making them efficient for spatial data. Parameters include: kernel size (e.g., 3√ó3), stride (step size), padding (border handling), and number of filters (output channels).";
    }
    
    if (lowerMessage.includes('pooling')) {
      return "Pooling layers reduce spatial dimensions while retaining important features. Max pooling takes the maximum value in each region, while average pooling takes the mean. This provides translation invariance and reduces computation. Common size: 2√ó2 with stride 2 (halves dimensions).";
    }
    
    if (lowerMessage.includes('relu') || lowerMessage.includes('activation')) {
      return "ReLU (Rectified Linear Unit) is f(x) = max(0, x). It's the most popular activation because it: 1) Prevents vanishing gradients, 2) Is computationally efficient, 3) Enables sparse activations. Other activations: Sigmoid, Tanh, Leaky ReLU, GELU. Output layers typically use Softmax for classification.";
    }
    
    if (lowerMessage.includes('dropout')) {
      return "Dropout randomly deactivates neurons during training (e.g., 50% dropout rate) to prevent overfitting. It forces the network to learn robust features that don't rely on specific neurons. At inference, all neurons are active but outputs are scaled. It's like training an ensemble of networks!";
    }
    
    if (lowerMessage.includes('batch norm')) {
      return "Batch Normalization normalizes layer inputs across mini-batches, which: 1) Accelerates training, 2) Allows higher learning rates, 3) Reduces sensitivity to initialization, 4) Acts as regularization. It normalizes to mean 0 and variance 1, then applies learned scale and shift parameters.";
    }
    
    if (lowerMessage.includes('transfer learning')) {
      return "Transfer learning uses pre-trained models (like AlexNet, ResNet on ImageNet) for new tasks. You can: 1) Use as feature extractor (freeze weights, train new classifier), 2) Fine-tune (unfreeze some layers, train with small learning rate). This works because early layers learn general features (edges, textures).";
    }
    
    if (lowerMessage.includes('overfitting')) {
      return "Overfitting occurs when a model learns training data too well, including noise. Prevention techniques: 1) Dropout, 2) Data augmentation, 3) L1/L2 regularization, 4) Early stopping, 5) Reduce model complexity, 6) More training data. Monitor validation loss - if it increases while training loss decreases, you're overfitting!";
    }
    
    if (lowerMessage.includes('imagenet')) {
      return "ImageNet is a large-scale dataset with 1.2M training images across 1000 classes. The ImageNet Large Scale Visual Recognition Challenge (ILSVRC) drove CNN innovation from 2010-2017. Top-5 error went from 28% (2010) to 2.25% (2017), surpassing human performance (~5%).";
    }
    
    if (lowerMessage.includes('parameter') || lowerMessage.includes('weight')) {
      return "Parameters are learnable values (weights and biases) that the network optimizes during training. Conv layer params = (kernel_height √ó kernel_width √ó input_channels + 1) √ó output_channels. FC layer params = (input_size + 1) √ó output_size. More parameters = more capacity but also more risk of overfitting.";
    }
    
    if (lowerMessage.includes('gradient') || lowerMessage.includes('backprop')) {
      return "Backpropagation computes gradients of the loss with respect to each parameter using the chain rule. Gradients indicate how to adjust weights to minimize loss. Vanishing gradients (very small) prevent learning in deep networks - solved by ReLU, skip connections, and batch norm. Exploding gradients are fixed by gradient clipping.";
    }
    
    if (lowerMessage.includes('optimizer') || lowerMessage.includes('sgd') || lowerMessage.includes('adam')) {
      return "Optimizers update weights using gradients. Popular ones: 1) SGD: Simple but effective with momentum, 2) Adam: Adaptive learning rates, works well out-of-box (most popular), 3) RMSprop: Good for RNNs, 4) AdamW: Adam with better weight decay. Learning rate is the most important hyperparameter!";
    }

    if (lowerMessage.includes('learning rate')) {
      return "Learning rate controls how much weights change per update. Too high = unstable training, overshooting. Too low = slow convergence, stuck in local minima. Common strategies: 1) Start with 0.001 (Adam) or 0.1 (SGD), 2) Learning rate decay/scheduling, 3) Warmup, 4) Cyclical learning rates.";
    }
    
    if (lowerMessage.includes('compare') || lowerMessage.includes('difference') || lowerMessage.includes('vs')) {
      return "**Model Comparisons:**\n‚Ä¢ **AlexNet (60M params)**: First deep CNN success, simple sequential architecture\n‚Ä¢ **VGG-16 (138M params)**: Uniform 3√ó3 convs, very deep but parameter-heavy\n‚Ä¢ **GoogLeNet (6.8M params)**: Efficient Inception modules, lowest parameters\n‚Ä¢ **ResNet-50 (25.6M params)**: Skip connections enable very deep networks, best accuracy\n\nKey trade-offs: Accuracy vs. Parameters vs. Computation. Modern choice is often ResNet for accuracy or MobileNet/EfficientNet for efficiency.";
    }
    
    if (lowerMessage.includes('how') && (lowerMessage.includes('work') || lowerMessage.includes('chatbot') || lowerMessage.includes('answer'))) {
      return "**How I work:** I'm a rule-based chatbot with a curated knowledge base! ü§ñ\n\n1. **Pattern Matching**: I analyze your message for keywords (e.g., 'alexnet', 'convolution', 'dropout')\n2. **Knowledge Base**: I have pre-written responses covering 50+ deep learning topics\n3. **Response Selection**: I match your question to the most relevant information\n\n**Note**: I'm not a real AI model - I'm a deterministic system designed to help you learn about neural networks! For production, you'd integrate with GPT-4, Claude, or similar LLMs via their APIs.";
    }
    
    if (lowerMessage.includes('skip connection') || lowerMessage.includes('residual')) {
      return "Skip connections (residual connections) add the input of a block directly to its output: y = F(x) + x. This allows gradients to flow directly backward, preventing vanishing gradients. Benefits: 1) Train much deeper networks (100+ layers), 2) Better gradient flow, 3) Learn identity mappings easily, 4) Improved accuracy. ResNet popularized this technique!";
    }
    
    if (lowerMessage.includes('data augmentation')) {
      return "Data augmentation artificially increases training data by applying transformations: 1) Geometric (rotation, flipping, cropping, scaling), 2) Color (brightness, contrast, saturation), 3) Noise injection, 4) Cutout/Mixup. Benefits: Reduces overfitting, improves generalization, makes models robust to variations. Essential for image classification!";
    }
    
    if (lowerMessage.includes('feature map') || lowerMessage.includes('channel')) {
      return "A feature map (or channel) is the output of applying one filter to an input. For example, a conv layer with 64 filters produces 64 feature maps. Each feature map detects specific patterns - early layers: edges/colors, middle layers: textures/parts, deep layers: objects/concepts. The depth (number of channels) represents representational capacity.";
    }
    
    if (lowerMessage.includes('inception') && lowerMessage.includes('module')) {
      return "An Inception module applies multiple filter sizes (1√ó1, 3√ó3, 5√ó5) in parallel, then concatenates results. This captures features at multiple scales simultaneously! The 1√ó1 convolutions before larger filters reduce computational cost (dimensionality reduction). It's like having multiple experts looking at the same data from different perspectives.";
    }
    
    if (lowerMessage.includes('dashboard') || lowerMessage.includes('calculator') || lowerMessage.includes('theory')) {
      return "The Dashboard has 4 powerful tabs:\n\n**1Ô∏è‚É£ Theory Tab**: Learn about Conv, Pooling, FC, and Dropout layers with formulas, properties, and numerical examples.\n\n**2Ô∏è‚É£ Calculator Tab**: Interactive tool to calculate output dimensions, parameters, FLOPs, and memory usage for convolutional layers. Try different inputs!\n\n**3Ô∏è‚É£ Examples Tab**: Real-world layer configurations from AlexNet, VGG, ResNet, and MobileNet. Click 'Try in Calculator' to experiment!\n\n**4Ô∏è‚É£ Data Transformation**: Visual guide showing how data flows through Conv, ReLU, BatchNorm, Pooling, Dropout, and FC layers with actual values!";
    }
    
    if (lowerMessage.includes('transformation') || lowerMessage.includes('data flow') || lowerMessage.includes('how data')) {
      return "**Data Transformation in Neural Networks**:\n\n1Ô∏è‚É£ **Input**: Raw pixel values (e.g., 5√ó5 image)\n2Ô∏è‚É£ **Convolution**: Extract features using kernels (3√ó3√ó2 filters)\n3Ô∏è‚É£ **ReLU**: Apply activation, zero out negatives\n4Ô∏è‚É£ **Batch Norm**: Normalize to mean=0, std=1 for stability\n5Ô∏è‚É£ **Pooling**: Downsample (e.g., 4√ó4 ‚Üí 2√ó2 max pool)\n6Ô∏è‚É£ **Dropout**: Randomly deactivate neurons (training only)\n7Ô∏è‚É£ **Flatten**: Convert 2D to 1D vector\n8Ô∏è‚É£ **FC**: Fully connected classification\n\nCheck the Dashboard's Data Transformation tab to see this with actual values!";
    }
    
    if (lowerMessage.includes('softmax') || lowerMessage.includes('output layer')) {
      return "**Softmax Activation** converts raw scores (logits) into probabilities that sum to 1.0:\n\nFormula: softmax(xi) = exp(xi) / Œ£exp(xj)\n\nExample:\n‚Ä¢ Input: [2.0, 1.0, 0.1]\n‚Ä¢ After exp: [7.39, 2.72, 1.11]\n‚Ä¢ Sum: 11.22\n‚Ä¢ Softmax: [0.659, 0.242, 0.099] ‚Üê Probabilities!\n\nUsed in final classification layer. The highest probability indicates the predicted class. Often paired with cross-entropy loss during training.";
    }
    
    if (lowerMessage.includes('flops') || lowerMessage.includes('computation') || lowerMessage.includes('efficiency')) {
      return "**FLOPs (Floating Point Operations)** measure computational cost:\n\nFor Conv Layer:\nFLOPs = Output_H √ó Output_W √ó Kernel_H √ó Kernel_W √ó Input_Channels √ó Output_Channels\n\n**Example**: Conv layer with 3√ó3 kernel, 64 input channels, 128 output channels, 56√ó56 output:\nFLOPs = 56 √ó 56 √ó 3 √ó 3 √ó 64 √ó 128 = 231M FLOPs\n\n**Why it matters**:\n‚Ä¢ Mobile devices: Need low FLOPs (<100M)\n‚Ä¢ Edge devices: Target <1B FLOPs\n‚Ä¢ Cloud servers: Can handle 10B+ FLOPs\n\nUse the Calculator tab to compute FLOPs for your layers!";
    }
    
    if (lowerMessage.includes('memory') || lowerMessage.includes('gpu') || lowerMessage.includes('vram')) {
      return "**Memory Usage in Neural Networks**:\n\n**1. Parameters (Weights)**:\n‚Ä¢ Conv: kernel_h √ó kernel_w √ó in_ch √ó out_ch √ó 4 bytes\n‚Ä¢ FC: input_size √ó output_size √ó 4 bytes\n\n**2. Activations (Forward Pass)**:\n‚Ä¢ Store all layer outputs for backprop\n‚Ä¢ batch_size √ó height √ó width √ó channels √ó 4 bytes\n\n**3. Gradients (Backward Pass)**:\n‚Ä¢ Same size as activations\n‚Ä¢ Temporary during training\n\n**Tips to reduce memory**:\n‚Ä¢ Smaller batch size\n‚Ä¢ Gradient checkpointing\n‚Ä¢ Mixed precision (FP16)\n‚Ä¢ Prune unnecessary layers\n\nCalculator tab shows parameter memory!";
    }
    
    if (lowerMessage.includes('stride') || lowerMessage.includes('padding')) {
      return "**Stride & Padding** control output dimensions:\n\n**Stride**: Step size when sliding filter\n‚Ä¢ Stride=1: Dense sampling, larger output\n‚Ä¢ Stride=2: Skip every other position, 2√ó smaller output\n‚Ä¢ Higher stride = faster but less detail\n\n**Padding**: Border pixels added\n‚Ä¢ Valid (no padding): Output shrinks\n‚Ä¢ Same (pad to maintain size): Output = Input\n‚Ä¢ Formula: pad = (kernel_size - 1) / 2\n\n**Output Size Formula**:\nOutput = ‚åä(Input + 2√óPad - Kernel) / Stride‚åã + 1\n\nExample: 32√ó32 input, 5√ó5 kernel, stride=1, pad=2\n‚Üí ‚åä(32 + 4 - 5) / 1‚åã + 1 = 32√ó32 output\n\nTry the Calculator tab!";
    }
    
    if (lowerMessage.includes('visualizer') || lowerMessage.includes('graph') || lowerMessage.includes('network view')) {
      return "**Network Visualizer Page Features**:\n\nüé® **Interactive Graph**:\n‚Ä¢ Visual representation of model architecture\n‚Ä¢ Zoom, pan, and navigate freely\n‚Ä¢ Click any layer node to see detailed specs\n\nüìä **Layer Details** (click a node):\n‚Ä¢ Type, input/output dimensions\n‚Ä¢ Kernel size, stride, padding\n‚Ä¢ Number of parameters\n‚Ä¢ Activation functions\n\nüîç **Special Features**:\n‚Ä¢ ResNet shows skip connections with branching paths\n‚Ä¢ Edge labels show stride information\n‚Ä¢ Animated connections between layers\n‚Ä¢ MiniMap for navigation\n\nü§ñ **Models Available**:\n‚Ä¢ AlexNet, ResNet-50, GoogLeNet, VGG-16\n\nExplore the Visualizer page from the top navigation!";
    }
    
    if (lowerMessage.includes('calculator') && lowerMessage.includes('use')) {
      return "**How to Use the Calculator Tab**:\n\n1Ô∏è‚É£ **Enter Input Dimensions**:\n‚Ä¢ Height, Width, Channels (e.g., 224√ó224√ó3 for RGB image)\n\n2Ô∏è‚É£ **Set Kernel Parameters**:\n‚Ä¢ Kernel Size (e.g., 3√ó3, 5√ó5, 7√ó7)\n‚Ä¢ Stride (typically 1 or 2)\n‚Ä¢ Padding (0 for valid, auto for same)\n‚Ä¢ Number of Filters (output channels)\n\n3Ô∏è‚É£ **View Results**:\n‚Ä¢ ‚úÖ Output Dimensions\n‚Ä¢ üìä Total Parameters\n‚Ä¢ ‚ö° FLOPs (computational cost)\n‚Ä¢ üíæ Memory Usage\n\nüí° **Pro Tip**: Try the example configurations from the Examples tab to see real-world settings from famous architectures!";
    }
    
    // Default responses with helpful suggestions
    const defaultResponses = [
      "I'd be happy to help! Try asking about:\n‚Ä¢ Specific models: 'Tell me about AlexNet', 'How does ResNet work?'\n‚Ä¢ Layers: 'What is convolution?', 'Explain pooling'\n‚Ä¢ Training: 'What is dropout?', 'How does backpropagation work?'\n‚Ä¢ Concepts: 'Compare the models', 'What is transfer learning?'",
      `Currently viewing: **${currentModel}**. Ask me:\n‚Ä¢ 'What makes ${currentModel} special?'\n‚Ä¢ 'How does it compare to other models?'\n‚Ä¢ 'What are the key layers?'\n‚Ä¢ Or ask about any deep learning concept!`,
      "üí° **Popular questions:**\n‚Ä¢ 'Explain skip connections'\n‚Ä¢ 'What is the difference between models?'\n‚Ä¢ 'How does dropout prevent overfitting?'\n‚Ä¢ 'What is data augmentation?'\n‚Ä¢ 'How do I choose a learning rate?'",
      "I have knowledge about:\n‚úì Models: AlexNet, ResNet, GoogLeNet, VGG\n‚úì Layers: Conv, Pooling, FC, Dropout, BatchNorm\n‚úì Training: Optimizers, Learning Rate, Regularization\n‚úì Concepts: Transfer Learning, Overfitting, Gradients\n\nWhat would you like to explore?",
    ];
    
    return defaultResponses[Math.floor(Math.random() * defaultResponses.length)];
  };

  const handleSend = () => {
    if (!input.trim()) return;

    const userMessage: ChatMessage = {
      id: Date.now().toString(),
      role: 'user',
      content: input,
      timestamp: new Date(),
    };

    setMessages((prev) => [...prev, userMessage]);
    setInput('');

    // Simulate AI response with delay
    setTimeout(() => {
      const aiMessage: ChatMessage = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: getAIResponse(input),
        timestamp: new Date(),
      };
      setMessages((prev) => [...prev, aiMessage]);
    }, 500);
  };

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSend();
    }
  };

  if (isMinimized) {
    return (
      <div className="fixed bottom-6 right-6 z-40">
        <button
          onClick={() => setIsMinimized(false)}
          className="bg-gradient-to-r from-blue-600 to-indigo-600 text-white p-4 rounded-full shadow-lg hover:shadow-xl transition-all flex items-center gap-2"
        >
          <MessageSquare className="w-6 h-6" />
          <span className="font-medium">Chat Assistant</span>
        </button>
      </div>
    );
  }

  return (
    <div
      className={`fixed ${
        isExpanded ? 'inset-4' : 'bottom-6 right-6 w-96 h-[600px]'
      } bg-white rounded-2xl shadow-2xl z-40 flex flex-col border border-gray-200 transition-all duration-300`}
    >
      {/* Header */}
      <div className="bg-gradient-to-r from-blue-600 to-indigo-600 text-white p-4 rounded-t-2xl flex items-center justify-between">
        <div className="flex items-center gap-3">
          <div className="bg-white bg-opacity-20 p-2 rounded-lg">
            <Bot className="w-6 h-6" />
          </div>
          <div>
            <h3 className="font-bold text-lg">Neural Network Assistant</h3>
            <p className="text-sm opacity-90">Ask me anything!</p>
          </div>
        </div>
        <div className="flex gap-2">
          <button
            onClick={() => setIsExpanded(!isExpanded)}
            className="p-2 hover:bg-white hover:bg-opacity-20 rounded-lg transition-colors"
          >
            {isExpanded ? <Minimize2 className="w-5 h-5" /> : <Maximize2 className="w-5 h-5" />}
          </button>
          <button
            onClick={() => setIsMinimized(true)}
            className="p-2 hover:bg-white hover:bg-opacity-20 rounded-lg transition-colors"
          >
            <X className="w-5 h-5" />
          </button>
        </div>
      </div>

      {/* Messages */}
      <div className="flex-1 overflow-y-auto p-4 space-y-4">
        {messages.map((message) => (
          <div
            key={message.id}
            className={`flex gap-3 ${message.role === 'user' ? 'flex-row-reverse' : 'flex-row'}`}
          >
            <div
              className={`flex-shrink-0 w-8 h-8 rounded-full flex items-center justify-center ${
                message.role === 'user' ? 'bg-blue-600' : 'bg-gradient-to-br from-indigo-500 to-purple-500'
              }`}
            >
              {message.role === 'user' ? (
                <User className="w-5 h-5 text-white" />
              ) : (
                <Bot className="w-5 h-5 text-white" />
              )}
            </div>
            <div
              className={`flex-1 px-4 py-3 rounded-2xl ${
                message.role === 'user'
                  ? 'bg-blue-600 text-white'
                  : 'bg-gray-100 text-gray-800'
              }`}
            >
              <div className="text-sm leading-relaxed whitespace-pre-wrap">
                {message.content.split('\n').map((line, i) => {
                  // Simple markdown-like formatting
                  if (line.startsWith('**') && line.includes(':**')) {
                    const parts = line.split(':**');
                    return (
                      <p key={i} className="font-bold mb-2 text-blue-700">
                        {parts[0].replace(/\*\*/g, '')}:
                      </p>
                    );
                  } else if (line.startsWith('**') && line.endsWith('**')) {
                    return (
                      <p key={i} className="font-bold mb-1">
                        {line.replace(/\*\*/g, '')}
                      </p>
                    );
                  } else if (line.startsWith('‚Ä¢') || line.startsWith('‚úì')) {
                    return (
                      <p key={i} className="ml-2 mb-1">
                        {line}
                      </p>
                    );
                  } else if (line.trim() === '') {
                    return <br key={i} />;
                  } else {
                    return <p key={i} className="mb-1">{line}</p>;
                  }
                })}
              </div>
              <p
                className={`text-xs mt-2 ${
                  message.role === 'user' ? 'text-blue-100' : 'text-gray-500'
                }`}
              >
                {message.timestamp.toLocaleTimeString()}
              </p>
            </div>
          </div>
        ))}
        <div ref={messagesEndRef} />
      </div>

      {/* Quick Questions (show when messages are minimal) */}
      {messages.length <= 1 && (
        <div className="px-4 pb-2">
          <p className="text-xs text-gray-500 mb-2">Quick questions:</p>
          <div className="flex flex-wrap gap-2">
            {[
              'What is the dashboard?',
              'How does data transformation work?',
              'Compare the models',
              'Explain batch normalization',
              'How to use calculator?',
              'What is dropout?',
            ].map((question, idx) => (
              <button
                key={idx}
                onClick={() => {
                  setInput(question);
                  setTimeout(() => handleSend(), 100);
                }}
                className="text-xs px-3 py-1.5 bg-blue-50 text-blue-600 rounded-full hover:bg-blue-100 transition-colors"
              >
                {question}
              </button>
            ))}
          </div>
        </div>
      )}

      {/* Input */}
      <div className="p-4 border-t border-gray-200">
        <div className="flex gap-2">
          <input
            type="text"
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyPress={handleKeyPress}
            placeholder="Ask about neural networks..."
            className="flex-1 px-4 py-3 border border-gray-300 rounded-xl focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-transparent"
          />
          <button
            onClick={handleSend}
            disabled={!input.trim()}
            className="bg-blue-600 text-white p-3 rounded-xl hover:bg-blue-700 disabled:bg-gray-300 disabled:cursor-not-allowed transition-colors"
          >
            <Send className="w-5 h-5" />
          </button>
        </div>
        <p className="text-xs text-gray-400 mt-2 text-center">
          üí° Rule-based chatbot with pre-programmed knowledge
        </p>
      </div>
    </div>
  );
};

export default Chatbot;
